{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.optimize\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "def bisect(func, fx, x_min, x_max, max_iter=100, tol=1e-6):\n",
    "    left = x_min\n",
    "    right = x_max\n",
    "    mid = np.zeros(len(fx))\n",
    "    \n",
    "    f_left = func(left)-fx\n",
    "    f_right = func(right)-fx\n",
    "    \n",
    "    update_indices = np.arange(len(fx))    \n",
    " \n",
    "    for it in range(max_iter):\n",
    "        if it == 0:\n",
    "            assert np.all(np.sign(f_left)!=np.sign(f_right)),\\\n",
    "            \"Function values of x_min and x_max must have different sign!\"\n",
    "        mid[update_indices] = (left[update_indices]+right[update_indices])/2\n",
    "        f_mid = func(mid[update_indices])-fx[update_indices]\n",
    "        # whether the left points have the same signs of function values as the midpoints\n",
    "        same_sign = np.sign(f_left)==np.sign(f_mid)\n",
    "        # the left points that need to be replaced by the midpoints\n",
    "        move2right = update_indices[same_sign]\n",
    "        move2left = update_indices[~same_sign]\n",
    "        # update\n",
    "        left[move2right] = mid[move2right]\n",
    "        f_left[move2right] = f_mid[same_sign]\n",
    "        right[move2left] = mid[move2left]\n",
    "        f_right[move2left] = f_mid[~same_sign]\n",
    "        update_indices = update_indices[np.abs(f_mid)>tol]\n",
    "        if len(update_indices) == 0: \n",
    "            # jump out of the loop if no midpoint needs to be updated\n",
    "            break\n",
    "    return mid\n",
    "\n",
    "class PlanarFlow(nn.Module):\n",
    "    \"\"\"\n",
    "    z_{k+1} = z_k + utanh(w^Tz_k+b)\n",
    "    w: projection\n",
    "    b: bias\n",
    "    u: expanding/contracting direction\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(PlanarFlow, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.direction = nn.Parameter(\n",
    "            nn.init.xavier_normal_(torch.empty(1, self.input_dim)))\n",
    "        self.projection = nn.Parameter(\n",
    "            nn.init.xavier_normal_(torch.empty(1, self.input_dim)))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        wxb = torch.sum(x*self.projection,dim=-1,keepdim=True)+self.bias\n",
    "        hx = torch.tanh(wxb)\n",
    "        Dhx = 1/(torch.cosh(wxb))**2\n",
    "        coef = (self.projection*self.direction).sum(dim=-1,keepdim=True)\n",
    "        return x + self.direction*hx, (1+Dhx*coef).abs()\n",
    "    \n",
    "    def modify(self):\n",
    "        coef = torch.sum(self.projection*self.direction)  # w^Tu\n",
    "        # in order to guarantee invertibility\n",
    "        # it suffices to have w^Tu > -1\n",
    "        # we follow the appendix to modify u\n",
    "        if coef <= -1:\n",
    "            m_coef = -1+torch.log(1+torch.exp(coef))\n",
    "            unit_proj = self.projection.data/torch.sum(self.projection.data**2).sqrt()\n",
    "            self.direction.data = self.direction.data+(m_coef-coef)*unit_proj\n",
    "            \n",
    "    def get_func(self, z):\n",
    "        coef = (self.projection*self.direction).sum().item()\n",
    "        bias = self.bias.item()\n",
    "        def func(x):\n",
    "            fx = x+coef*np.tanh(x+bias)\n",
    "            return fx-z\n",
    "        return func\n",
    "        \n",
    "    def inverse_base(self, z):\n",
    "        with torch.no_grad():\n",
    "            coef = (self.projection*self.direction).sum().item()\n",
    "            fx = np.sum(self.projection.cpu().numpy()*z)\n",
    "            f = self.get_func(fx)\n",
    "            parallel = scipy.optimize.bisect(self.get_func(fx), fx-coef, fx+coef)\n",
    "            hx = np.tanh(parallel+self.bias.item())\n",
    "            return z - self.direction.cpu().numpy()*hx\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        coef = (self.projection*self.direction).sum().item()\n",
    "        bias = self.bias.item()\n",
    "#         def mapping(x):\n",
    "#             fx = x+coef*np.tanh(x+bias)\n",
    "#             return fx\n",
    "        out = []\n",
    "        for row in np.vsplit(z, len(z)):\n",
    "            out.append(self.inverse_base(row))\n",
    "        return np.vstack(out)\n",
    "        fx = np.sum(self.projection.cpu().numpy()*z, axis=-1)\n",
    "        parallel = bisect(mapping, fx, x_min=fx-coef, x_max=fx+coef)\n",
    "        hx = np.tanh(parallel+bias)\n",
    "        return z - self.direction.cpu().numpy()*hx[:, None]\n",
    "\n",
    "\n",
    "class NormalizingFlow(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        n_maps,\n",
    "        transformation=\"planar\"\n",
    "    ):\n",
    "        super(NormalizingFlow, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.n_maps = n_maps\n",
    "        self.transformation = transformation\n",
    "        self.flows = nn.Sequential(OrderedDict(\n",
    "            (f\"flow_{i}\", self.get_flow() )\n",
    "            for i in range(self.n_maps)\n",
    "        ))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.map_id = 0\n",
    "        return self\n",
    "        \n",
    "    def __next__(self):\n",
    "        if self.map_id < self.n_maps:\n",
    "            flow = getattr(self.flows, f\"flow_{self.map_id}\")\n",
    "            self.map_id += 1\n",
    "            return flow\n",
    "        else:\n",
    "            raise StopIteration\n",
    "    \n",
    "    def get_flow(self):\n",
    "        if self.transformation == \"planar\":\n",
    "            return PlanarFlow(self.input_dim)\n",
    "        elif self.transformation == \"radial\":\n",
    "            pass\n",
    "    def forward(self, x):\n",
    "        logp = 0\n",
    "        for flow in self:\n",
    "            x, det = flow(x)\n",
    "            logp += torch.log(det).mean()\n",
    "        logp += -(x.size(1)/2)*np.log(2*np.pi)\n",
    "        logp += -(x**2).sum(dim=1).mean()/2\n",
    "        return -logp\n",
    "    def modify(self):\n",
    "        for flow in self:\n",
    "            flow.modify()\n",
    "    def inverse(self, z):\n",
    "        with torch.no_grad():\n",
    "            x = np.array(z.clone())\n",
    "            for flow in self:\n",
    "                x = flow.inverse(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "root = \"~/datasets\"\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.MNIST(root=root, download=False, train=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=512)\n",
    "\n",
    "# digit = 1\n",
    "# digit_data = train_data.data[train_data.targets==digit]/255\n",
    "\n",
    "# class SingleDigit(Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.data[idx]\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "# train_loader = DataLoader(SingleDigit(digit_data), batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0/10 epochs:   0%|                                                                              | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (784) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-03fea302e9c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mtrain_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mneg_logp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplanar_flow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mneg_logp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bravo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-80f99679381c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mlogp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mflow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[0mlogp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mlogp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bravo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-80f99679381c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mwxb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mDhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcosh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (784) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import SGD, Adam\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = 28*28\n",
    "n_layers = 10\n",
    "\n",
    "planar_flow = NormalizingFlow(input_dim, n_layers)\n",
    "planar_flow.to(device)\n",
    "\n",
    "n_epochs = 10\n",
    "# optimizer = SGD(planar_flow.parameters(), lr=0.01, momentum=0.8, weight_decay=0, nesterov=True)\n",
    "optimizer = Adam(planar_flow.parameters(), lr=0.001, weight_decay=5e-3)\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    with tqdm(train_loader, desc=f\"{e}/{n_epochs} epochs\") as t:\n",
    "        train_neg_logp = 0\n",
    "        train_total = 0\n",
    "        for i, x in enumerate(t):\n",
    "            neg_logp = planar_flow(x.flatten(start_dim=1).to(device))\n",
    "            optimizer.zero_grad()\n",
    "            neg_logp.backward()\n",
    "            optimizer.step()\n",
    "            planar_flow.modify()\n",
    "            train_neg_logp += neg_logp.item()*x.size(0)\n",
    "            train_total += x.size(0)\n",
    "            t.set_postfix({\"train_neg_logp\": train_neg_logp/train_total})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1234)\n",
    "toy_data = np.random.laplace(size=(100000, 2))\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "_ = plt.hist2d(\n",
    "    toy_data[:,0], toy_data[:,1], \n",
    "    range=[[-3,3],[-3,3]],\n",
    "    bins=(20, 20),\n",
    "    density=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/30 epochs: 100%|████████████████████████████████████████████████| 10/10 [00:00<00:00, 65.79it/s, train_neg_logp=11.4]\n",
      "2/30 epochs: 100%|████████████████████████████████████████████████| 10/10 [00:00<00:00, 62.50it/s, train_neg_logp=11.1]\n",
      "3/30 epochs: 100%|████████████████████████████████████████████████| 10/10 [00:00<00:00, 62.89it/s, train_neg_logp=10.8]\n",
      "4/30 epochs: 100%|████████████████████████████████████████████████| 10/10 [00:00<00:00, 64.94it/s, train_neg_logp=10.5]\n",
      "5/30 epochs: 100%|████████████████████████████████████████████████| 10/10 [00:00<00:00, 63.70it/s, train_neg_logp=10.2]\n",
      "6/30 epochs: 100%|████████████████████████████████████████████████| 10/10 [00:00<00:00, 54.04it/s, train_neg_logp=9.86]\n",
      "7/30 epochs: 100%|████████████████████████████████████████████████| 10/10 [00:00<00:00, 39.68it/s, train_neg_logp=9.57]\n",
      "8/30 epochs: 100%|████████████████████████████████████████████████| 10/10 [00:00<00:00, 42.92it/s, train_neg_logp=9.27]\n",
      "9/30 epochs: 100%|████████████████████████████████████████████████| 10/10 [00:00<00:00, 62.50it/s, train_neg_logp=8.99]\n",
      "10/30 epochs: 100%|████████████████████████████████████████████████| 10/10 [00:00<00:00, 61.73it/s, train_neg_logp=8.7]\n",
      "11/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 49.75it/s, train_neg_logp=8.42]\n",
      "12/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 44.45it/s, train_neg_logp=8.14]\n",
      "13/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 56.50it/s, train_neg_logp=7.88]\n",
      "14/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 64.52it/s, train_neg_logp=7.62]\n",
      "15/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 62.50it/s, train_neg_logp=7.36]\n",
      "16/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 65.36it/s, train_neg_logp=7.12]\n",
      "17/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 68.95it/s, train_neg_logp=6.88]\n",
      "18/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 56.49it/s, train_neg_logp=6.65]\n",
      "19/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 62.50it/s, train_neg_logp=6.43]\n",
      "20/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 42.92it/s, train_neg_logp=6.22]\n",
      "21/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 36.23it/s, train_neg_logp=6.02]\n",
      "22/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 58.14it/s, train_neg_logp=5.83]\n",
      "23/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 63.69it/s, train_neg_logp=5.64]\n",
      "24/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 65.80it/s, train_neg_logp=5.47]\n",
      "25/30 epochs: 100%|████████████████████████████████████████████████| 10/10 [00:00<00:00, 67.11it/s, train_neg_logp=5.3]\n",
      "26/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 67.11it/s, train_neg_logp=5.15]\n",
      "27/30 epochs: 100%|██████████████████████████████████████████████████| 10/10 [00:00<00:00, 68.03it/s, train_neg_logp=5]\n",
      "28/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 55.87it/s, train_neg_logp=4.86]\n",
      "29/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 58.14it/s, train_neg_logp=4.73]\n",
      "30/30 epochs: 100%|███████████████████████████████████████████████| 10/10 [00:00<00:00, 51.02it/s, train_neg_logp=4.62]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = 2\n",
    "n_layers = 5\n",
    "\n",
    "planar_flow = NormalizingFlow(input_dim, n_layers)\n",
    "planar_flow.to(device)\n",
    "\n",
    "n_epochs = 30\n",
    "optimizer = Adam(planar_flow.parameters(), lr=0.001, weight_decay=5e-3)\n",
    "\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    def __len__(self):\n",
    "        return len(data)\n",
    "\n",
    "ds = ToyDataset(toy_data)\n",
    "train_loader = DataLoader(ds, batch_size=1000)\n",
    "    \n",
    "for e in range(n_epochs):\n",
    "    with tqdm(train_loader, desc=f\"{e+1}/{n_epochs} epochs\") as t:\n",
    "        train_neg_logp = 0\n",
    "        train_total = 0\n",
    "        for i, x in enumerate(t):\n",
    "            neg_logp = planar_flow(x.flatten(start_dim=1).to(device))\n",
    "            optimizer.zero_grad()\n",
    "            neg_logp.backward()\n",
    "            optimizer.step()\n",
    "            planar_flow.modify()\n",
    "            train_neg_logp += neg_logp.item()*x.size(0)\n",
    "            train_total += x.size(0)\n",
    "            t.set_postfix({\"train_neg_logp\": train_neg_logp/train_total})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAFpCAYAAACI3gMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAS90lEQVR4nO3df6jd9X3H8dfr3Jz7K7lRo8G6GKow52pFKguObmNbp9vSUmq7UaiUrtDCZX+UWdjAdmGTbggbjjLoBltAWQfOUmbFUi3VsBYn1N+kLhotmVsx9UfUmN/J/XXe+yM3kGnMvbnvj/ne+87zAYGc3PN9n/f3/Hjdb77nnPfHESEAQB29rhsAALRFsANAMQQ7ABRDsANAMQQ7ABRDsANAMelgtz1q+3HbP7H9rO2vtWgMALA0zn6O3bYlrY6IQ7b7kh6RdHNEPNqiQQDAmVmVLRDHfzMcmr/Yn//Dt54AoCNNzrHbHrK9XdIeSQ9FxGMt6gIAzlz6iF2SImJO0odsny/pXttXR8SOk69je1LSpCQNaehXxrW2xU0Dy4/ddQdygx5iMGjRSLIJ/vN/soN6642IWL/Q9dLn2N9R0L5V0uGI+Lt3u85ar4tf9fVNbxcJbvAft2gQAkkeGuq6heNa3J9JvdGRdI3B0aP5RpL3RczOdN7D8Ua6f35L0rb496ciYtNC12vxqZj180fqsj0m6QZJz2frAgCWpsWpmEskfdP2kI7/ovh2RHyvQV0AwBK0+FTMM5KubdALAKCB7k8GAgCaItgBoBiCHQCKIdgBoBiCHQCKIdgBoBiCHQCKIdgBoBiCHQCKIdgBoBiCHQCKaTKPHSubey3mhy+TkblJHh7OF5mby22/Kv+yjOnpdI0W427dz+1LZO/LVlbY6F+O2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIphoY0utRje30CLxQx6Y2Op7d1gcQlF5EsM8osh9NZflCvQYJGMODaVruGh/OIpMZXro80iMHnLZsGPRVoeyQIAaIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZ57F2K/OzvFjPde8PD6RqRnCHem1iT7kENZrq3mP4d69bmepiezffw0svpGk0ek6Ts80qSYpCf07/ScMQOAMWkg932Rts/tL3T9rO2b27RGABgaVqcipmV9KcR8bTtCUlP2X4oIp5rUBsAcIbSR+wR8UpEPD3/94OSdkrakK0LAFiapm+e2r5M0rWSHjvFzyYlTUrSqMZb3iwA4CTN3jy1vUbSPZK+HBEH3v7ziNgaEZsiYlNfI61uFgDwNk2C3XZfx0P9roj4TouaAIClafGpGEu6Q9LOiPh6viUAQEaLI/Zfl/Q5Sb9je/v8n481qAsAWIL0m6cR8YjafGEPANAA3zwFgGIIdgAohmAHgGIIdgAohmAHgGKYx56RnIXe6zeYH95glrrHRtM1NJL8NvFo/tvIMZ6vMRjrp2tMXZDrY2gmP6e/v7rBfZGuIPUOHE1t7wbz2B35eeyDo7n9ONs4YgeAYgh2ACiGYAeAYgh2ACiGYAeAYgh2ACiGYAeAYgh2ACiGYAeAYgh2ACiGYAeAYgh2ACiGYAeAYgh2ACiGYAeAYgh2ACiGhTY6FHNz6Rpu0If6+cUl5jZcmNp+al1+YYiZNUPpGvsvzx/rjL2RW9hhKL+2hNbM5heXGN79Vr6RBovJpDV4nWUX1ZEkRYulSxaHI3YAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKGYZDEvuSIP5yu7lpqF7JD+D3BNr0jXmNq5P19h/xerU9scuyE+WP7QxP4N81ZF0Cb35kanU9v3/HU33MHRsOF1j1cHxdA1PzeS2H8rP2M8/KyRNNxiSfxZxxA4AxRDsAFAMwQ4AxRDsAFAMwQ4AxRDsAFBMk2C3faftPbZ3tKgHAFi6Vkfs/yJpc6NaAICEJsEeEQ9L2tuiFgAg56x989T2pKRJSRpV/httAIBTO2tvnkbE1ojYFBGb+sp/lR4AcGp8KgYAiiHYAaCYVh93vFvSjyVdaXu37S+2qAsAOHNN3jyNiJta1AEA5K3MeezLYJa6JPXOW5uukbY2P499ZiI/u3tqbe7+3H/lXLqHFnrvP5YvMp2bIT43kp8gvveD+dfIyL6xdI3Rl3Kz6TWcf27GkQZD9lcYzrEDQDEEOwAUQ7ADQDEEOwAUQ7ADQDEEOwAUQ7ADQDEEOwAUQ7ADQDEEOwAUQ7ADQDEEOwAUQ7ADQDEEOwAUQ7ADQDEEOwAUszIX2ohBgyK5xRAkaXDgUK6DC85L96C5/H0xO57//X7w8tziEJdd+Wq6h+su+lm6Rt/5BT9GerOp7e8a25TuYfD8RLrG7Or8a0QzufticPRouoXBseRiH1KTxX3a5NbicMQOAMUQ7ABQDMEOAMUQ7ABQDMEOAMUQ7ABQDMEOAMUQ7ABQDMEOAMUQ7ABQDMEOAMUQ7ABQDMEOAMUQ7ABQDMEOAMV0N489Md/YPadvPga5+eGS1BtN3n3jY+kepjecn64xszr/+31uIjfH/OLx3Gx7Sfrcuh+na3ywP56uMbn711LbX3bh3nQP/70qP499am3+ebEm+Trrrc4/HjE9k68xm6/RZqb74q7GETsAFEOwA0AxBDsAFEOwA0AxBDsAFEOwA0AxBDsAFEOwA0AxBDsAFEOwA0AxBDsAFNMk2G1vtv2C7V22v9KiJgBgadLBbntI0j9K+qikqyTdZPuqbF0AwNK0OGK/TtKuiHgxIqYlfUvSjQ3qAgCWoEWwb5D00kmXd8//GwCgAy3msZ9qOPo7pgbbnpQ0KUmjGpdikLjF/tK3PVGil7j9EzXGRnMFZnMzzCVp+vz8fXHk4vzvd6+eTm0/3JtN9/DqbH4G+S+tmkrXuHj4QGr7bc/9crqHiVfTJbT6lQYzyGdzj+vg8JF8Dy00maWez5zFanHEvlvSxpMuXyrp5bdfKSK2RsSmiNjU10iDmwUAnEqLYH9C0hW2L7c9LOkzkr7boC4AYAnSp2IiYtb2lyT9QNKQpDsj4tl0ZwCAJWmy5mlEPCDpgRa1AAA5fPMUAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgmCZDwM62mG2wAECDwflxLLcog9euTfew+n9yizpI0uGLL0jXeOfSKmfmxQMXplv4i32fTNf4xgfuTtf40WtX5Aocyb8s+4fTJTS892i+yKrkvkTyiSXJ/fz9uVwyZ7GvM47YAaAYgh0AiiHYAaAYgh0AiiHYAaAYgh0AiiHYAaAYgh0AiiHYAaAYgh0AiiHYAaAYgh0AiiHYAaAYgh0AiiHYAaCYFTmPvcVc416DGc3uJfuYnk73MBjOz3Qff30u38djo6ntX/nweekeLlp3KF3js49/MV1j+q3cfbHmxaF0D6P7BukavcO59QYkSQdzj4mz89wlzR1qMJy+hcg/JovFETsAFEOwA0AxBDsAFEOwA0AxBDsAFEOwA0AxBDsAFEOwA0AxBDsAFEOwA0AxBDsAFEOwA0AxBDsAFEOwA0AxBDsAFLMy57E3EIPIF0nOU/dUfh5772h+ZvbI3n66xuyoU9sfeGMk3cObr+bmoEtS5Eehq380d18MHcv3MLHrQL7IW/vTJWIq9/wcHD2a7sG93OMhSZFfsuCs4ogdAIpJBbvtT9t+1vbA9qZWTQEAli57xL5D0h9IerhBLwCABlLn2CNipyTZ+XNYAIA2ztqbp7YnJU1K0qjGz9bNAsA5Z8Fgt71N0vtO8aMtEXHfYm8oIrZK2ipJa72uwUdSAACnsmCwR8QNZ6MRAEAbfNwRAIrJftzxU7Z3S/qwpPtt/6BNWwCApcp+KuZeSfc26gUA0ACnYgCgGIIdAIoh2AGgGIIdAIoh2AGgmJU5jz0GDYrkB29nZ7pnZ1VLkufyX+Id9PO/3+dGcvOCLtjRYGZ2g5FFQ9P5+3N8z0xq+7GfH0r34EP5OeaDg/k+spqsm3AO4ogdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgGIIdAIoh2AGgmBW50IaHGiySMTfXeR9Nenh9b7rG8PhwusaFew6ntp89bzTdQ4tFR6LBoc6qA7kFVLw/v8BFvPlWuoYaPD8HM7O5Ak0W1Tn3cMQOAMUQ7ABQDMEOAMUQ7ABQDMEOAMUQ7ABQDMEOAMUQ7ABQDMEOAMUQ7ABQDMEOAMUQ7ABQDMEOAMUQ7ABQDMEOAMV0N4/dS/+d0mKOeRPh3PYN9qPFfdF75c10DQ33U5v3Dx/L9+Dk4yEpXns930d2Tv9scoa5pBjk55g3eZ0xT70THLEDQDEEOwAUQ7ADQDEEOwAUQ7ADQDEEOwAUkwp227fbft72M7bvtX1+q8YAAEuTPWJ/SNLVEXGNpJ9K+mq+JQBARirYI+LBiDjxbYpHJV2abwkAkNHyHPsXJH3/3X5oe9L2k7afnNFUw5sFAJxswZECtrdJet8pfrQlIu6bv84WSbOS7nq3OhGxVdJWSVrrdbGkbgEAC1ow2CPihtP93PbnJX1c0vURQWADQMdSQ8Bsb5Z0i6TfiogjbVoCAGRkz7H/g6QJSQ/Z3m77nxr0BABISB2xR8QvtmoEANBGd/PYM3OaE7Pcm9z+iTaGh3MtzOTnbg/2H0jXWDU+lq6hI0dz2w+Wx9sz2cdUkub27eu8h5ieztdo8Jg4O5t+uay9sMIwUgAAiiHYAaAYgh0AiiHYAaAYgh0AiiHYAaAYgh0AiiHYAaAYgh0AiiHYAaAYgh0AiiHYAaAYgh0AiiHYAaAYgh0AiiHYAaCY7hbayGiwSEaLxToGx6aSLTjdQwtzr+1J1+hNTKS2j6ncfSnlF3WQ2ixQkX1uZZ9Xktq8RhqIAceOXeBeB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiVuY89haWxbzq/PzwFjPdY24uXWNu377U9l7VT/cQM7PpGi2eFy3uzzKWxevs3MMROwAUQ7ADQDEEOwAUQ7ADQDEEOwAUQ7ADQDEEOwAUQ7ADQDEEOwAUQ7ADQDEEOwAUkwp2239t+xnb220/aPsXWjUGAFia7BH77RFxTUR8SNL3JP1lg54AAAmpYI+IAyddXC0pcu0AALLSY3tt3ybpjyTtl/SRdEcAgBRHnP4g2/Y2Se87xY+2RMR9J13vq5JGI+LWd6kzKWly/uLVknYsqeOV4SJJb3TdxHuo8v5V3jeJ/VvproyIiYWutGCwL5bt90u6PyKuXsR1n4yITU1ueBli/1auyvsmsX8r3WL3L/upmCtOuvgJSc9n6gEA8rLn2P/G9pWSBpJ+JumP8y0BADJSwR4Rf7jETbdmbncFYP9Wrsr7JrF/K92i9q/ZOXYAwPLASAEAKKazYK88jsD27bafn9+/e22f33VPLdn+tO1nbQ9sl/kEgu3Ntl+wvcv2V7rupyXbd9reY7vkx4xtb7T9Q9s755+bN3fdUyu2R20/bvsn8/v2tQW36epUjO21J765avtPJF0VESXefLX9e5L+IyJmbf+tJEXELR231YztD+j4G+b/LOnPIuLJjltKsz0k6aeSflfSbklPSLopIp7rtLFGbP+mpEOS/nUxH0leaWxfIumSiHja9oSkpyR9ssLjZ9uSVkfEIdt9SY9IujkiHn23bTo7Yq88jiAiHoyI2fmLj0q6tMt+WouInRHxQtd9NHadpF0R8WJETEv6lqQbO+6pmYh4WNLervt4r0TEKxHx9PzfD0raKWlDt121Eccdmr/Yn/9z2rzs9By77dtsvyTps6o7QOwLkr7fdRNY0AZJL510ebeKBMO5xvZlkq6V9Fi3nbRje8j2dkl7JD0UEafdt/c02G1vs73jFH9ulKSI2BIRGyXdJelL72UvrS20b/PX2SJpVsf3b0VZzP4V41P8W5n/RZ4rbK+RdI+kL7/trMCKFhFz81N0L5V0ne3Tnk5LDwFboJkbFnnVf5N0v6RTzplZjhbaN9ufl/RxSdfHCvxM6Rk8dlXslrTxpMuXSnq5o16wBPPnn++RdFdEfKfrft4LEbHP9o8kbdZp5m11+amYsuMIbG+WdIukT0TEka77waI8IekK25fbHpb0GUnf7bgnLNL8G4x3SNoZEV/vup+WbK8/8ck622OSbtACednlp2LukfT/xhFExM87aaYx27skjUh6c/6fHq3yiR9Jsv0pSd+QtF7SPknbI+L3u+0qz/bHJP29pCFJd0bEbR231IztuyX9to5PP3xN0q0RcUenTTVk+zck/aek/9LxTJGkP4+IB7rrqg3b10j6po4/L3uSvh0Rf3XabVbgWQIAwGnwzVMAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4BiCHYAKIZgB4Bi/g8mCT5yce+iVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.randn((10000, 2))\n",
    "x = planar_flow.inverse(z)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "_ = plt.hist2d(\n",
    "    x[:,0], x[:,1], \n",
    "    range=[[-3,3],[-3,3]],\n",
    "    bins=(20, 20),\n",
    "    density=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
